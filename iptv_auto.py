#!/usr/bin/env python3
# å…¨è‡ªåŠ¨IPTVï¼šæ‹‰å–+æ ¡éªŒ+ä¼˜é€‰+ç”Ÿæˆã€æ’­æ”¾å™¨å‹å¥½ç‰ˆã€‘
# ç”Ÿæˆçš„playlist.m3u8å¯ç›´æ¥å¯¼å…¥æ’­æ”¾å™¨ï¼Œæ˜¾ç¤ºåˆ†ç±»é¢‘é“åˆ—è¡¨ï¼Œä¸€é”®æ¢å°
import requests
import re
import os
import time
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse

# ===================== æ ¸å¿ƒé…ç½®ï¼ˆæ— éœ€ä¿®æ”¹ï¼‰=====================
# ä¼˜è´¨å…¬å…±IPTVæºï¼ˆå·²ç­›é€‰ï¼Œä¿è¯æ’­æ”¾å™¨å…¼å®¹æ€§ï¼‰
PUBLIC_IPTV_SOURCES = [
    "https://raw.githubusercontent.com/51itgg/IPTV/main/m3u/iptv.m3u8",
    "https://raw.githubusercontent.com/ccf-2012/IPTV/main/IPTV.m3u8",
    "https://raw.githubusercontent.com/zhuhansan666/IPTV/main/iptv.m3u8",
    "https://raw.githubusercontent.com/yuanguozheng/IPTV/main/iptv.m3u8"
]
THREAD_NUM = 15          # å¹¶å‘æ ¡éªŒçº¿ç¨‹ï¼ˆå¹³è¡¡é€Ÿåº¦ä¸ç¨³å®šæ€§ï¼‰
TIMEOUT = 6              # æºæ ¡éªŒè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
KEEP_BEST_N = 1          # åŒé¢‘é“ä¿ç•™æœ€ä¼˜æºæ•°é‡
FILTER_KEYWORDS = ["å¹¿å‘Š", "æµ‹è¯•", "è´­ç‰©", "ä»˜è´¹", "VIP", "ç ´è§£", "æˆäºº"]
OUTPUT_FILE = "playlist.m3u8"

# é¢‘é“åˆ†ç±»ï¼ˆæ’­æ”¾å™¨ä¼šè¯†åˆ«#EXTGRPæ ‡ç­¾æ˜¾ç¤ºåˆ†ç±»åˆ—è¡¨ï¼‰
CHANNEL_CATEGORIES = {
    "å¤®è§†": ["CCTV-", "å¤®è§†"],
    "å«è§†": ["æ¹–å—å«è§†", "æµ™æ±Ÿå«è§†", "ä¸œæ–¹å«è§†", "æ±Ÿè‹å«è§†", "åŒ—äº¬å«è§†", "å®‰å¾½å«è§†", "å±±ä¸œå«è§†", "å¤©æ´¥å«è§†", "æ¹–åŒ—å«è§†", "æ²³å—å«è§†", "æ±Ÿè¥¿å«è§†", "å››å·å«è§†", "é‡åº†å«è§†", "å¹¿ä¸œå«è§†"],
    "åœ°æ–¹å°": ["ç æ±Ÿ", "å—æ–¹", "æ·±åœ³", "å¹¿å·", "æ­å·", "å—äº¬", "æˆéƒ½", "æ­¦æ±‰", "é•¿æ²™", "é’å²›", "å¤§è¿", "å¦é—¨"],
    "ç‰¹è‰²é¢‘é“": ["å¡é€š", "ä½“è‚²", "åŠ¨æ¼«", "æ–°é—»", "ç”µå½±", "ç»¼è‰º"]
}

# ===================== å·¥å…·å‡½æ•° =====================
def pull_public_source(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36"}
        res = requests.get(url, headers=headers, timeout=12)
        res.raise_for_status()
        if res.text.startswith("#EXTM3U"):
            print(f"âœ… æ‹‰å–æˆåŠŸï¼š{url}")
            return res.text
        else:
            print(f"âŒ éæ ‡å‡†m3u8ï¼š{url}")
            return None
    except Exception as e:
        print(f"âŒ æ‹‰å–å¤±è´¥ {url}ï¼š{str(e)[:50]}")
        return None

def parse_m3u8(m3u8_content):
    channels = {}
    lines = [line.strip() for line in m3u8_content.split("\n") if line.strip()]
    for i in range(len(lines)):
        if lines[i].startswith("#EXTINF:") and i+1 < len(lines) and not lines[i+1].startswith("#"):
            name_match = re.search(r',(.*)$', lines[i])
            if not name_match:
                continue
            channel_name = name_match.group(1).strip()
            if any(key in channel_name for key in FILTER_KEYWORDS):
                continue
            play_url = lines[i+1].strip()
            if play_url.startswith(("http://", "https://")) and (".m3u8" in play_url or "hls" in play_url or "ts" in play_url):
                if channel_name not in channels:
                    channels[channel_name] = []
                if play_url not in channels[channel_name]:
                    channels[channel_name].append(play_url)
    print(f"ğŸ“Œ è§£æå‡º {len(channels)} ä¸ªåŸå§‹é¢‘é“")
    return channels

def check_source(channel_name, url):
    try:
        start_time = time.time()
        # è½»é‡æ ¡éªŒï¼šåªè¯·æ±‚å¤´ï¼Œä¸ä¸‹è½½å†…å®¹
        requests.head(url, timeout=TIMEOUT, allow_redirects=True, stream=True)
        delay = round((time.time() - start_time) * 1000, 2)
        print(f"âœ… [{channel_name}] æœ‰æ•ˆ | å»¶è¿Ÿï¼š{delay}ms | {url[:60]}...")
        return (channel_name, url, delay)
    except Exception:
        return None

# åŒ¹é…é¢‘é“åˆ†ç±»ï¼ˆç»™æ’­æ”¾å™¨æ˜¾ç¤ºåˆ†ç±»åˆ—è¡¨ï¼‰
def get_channel_category(channel_name):
    for category, keywords in CHANNEL_CATEGORIES.items():
        if any(keyword in channel_name for keyword in keywords):
            return category
    return "å…¶ä»–é¢‘é“"

# ===================== ä¸»é€»è¾‘ =====================
def main():
    print("===== 1. æ‹‰å–å…¬å…±IPTVæº =====")
    all_m3u8 = []
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(pull_public_source, url) for url in PUBLIC_IPTV_SOURCES]
        for future in as_completed(futures):
            res = future.result()
            if res:
                all_m3u8.append(res)
    if not all_m3u8:
        print("âŒ æ— æœ‰æ•ˆæºï¼Œé€€å‡º")
        return
    all_m3u8_content = "\n".join(all_m3u8)

    print("===== 2. è§£æå¹¶å»é‡é¢‘é“ =====")
    channels = parse_m3u8(all_m3u8_content)
    if not channels:
        print("âŒ æ— æœ‰æ•ˆé¢‘é“ï¼Œé€€å‡º")
        return

    print("===== 3. æ ¡éªŒæºå¯ç”¨æ€§ï¼ˆæµ‹é€Ÿï¼‰ =====")
    valid_sources = []
    with ThreadPoolExecutor(max_workers=THREAD_NUM) as executor:
        futures = []
        for name, urls in channels.items():
            for url in urls:
                futures.append(executor.submit(check_source, name, url))
        for future in as_completed(futures):
            res = future.result()
            if res:
                valid_sources.append(res)
    if not valid_sources:
        print("âŒ æ— æœ‰æ•ˆæ’­æ”¾æºï¼Œé€€å‡º")
        return
    print(f"ğŸ“Œ æ ¡éªŒå‡º {len(valid_sources)} ä¸ªæœ‰æ•ˆæ’­æ”¾æº")

    print("===== 4. åŒé¢‘é“ä¼˜é€‰ =====")
    optimized_channels = {}
    for name, url, delay in valid_sources:
        if name not in optimized_channels:
            optimized_channels[name] = []
        optimized_channels[name].append((url, delay))
    # æŒ‰å»¶è¿Ÿæ’åºï¼Œä¿ç•™æœ€ä¼˜Nä¸ª
    for name in optimized_channels:
        optimized_channels[name].sort(key=lambda x: (x[1], -len(x[0])))
        optimized_channels[name] = optimized_channels[name][:KEEP_BEST_N]
    print(f"ğŸ“Œ ä¼˜é€‰åä¿ç•™ {len(optimized_channels)} ä¸ªå¯ç”¨é¢‘é“")

    print("===== 5. ç”Ÿæˆæ’­æ”¾å™¨å‹å¥½çš„m3u8 =====")
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        # æ ‡å‡†å¤´éƒ¨ï¼ˆå¸¦EPGèŠ‚ç›®å•ï¼Œæ’­æ”¾å™¨å¯æ˜¾ç¤ºèŠ‚ç›®é¢„å‘Šï¼‰
        f.write("#EXTM3U x-tvg-url=\"https://epg.112114.xyz/epg.xml\",charset=\"utf-8\"\n\n")
        
        # æŒ‰åˆ†ç±»ç”Ÿæˆï¼ˆæ’­æ”¾å™¨ä¼šè¯†åˆ«#EXTGRPæ˜¾ç¤ºåˆ†ç±»ï¼‰
        categorized_channels = {}
        for name, sources in optimized_channels.items():
            category = get_channel_category(name)
            if category not in categorized_channels:
                categorized_channels[category] = []
            categorized_channels[category].append((name, sources))
        
        # å†™å…¥åˆ†ç±»å’Œé¢‘é“
        for category, channels in sorted(categorized_channels.items()):
            f.write(f"#EXTGRP:{category}\n")  # æ’­æ”¾å™¨åˆ†ç±»æ ‡ç­¾
            for name, sources in sorted(channels, key=lambda x: x[0]):
                for url, _ in sources:
                    # å¸¦logo+åˆ†ç±»çš„æ ‡å‡†æ ¼å¼
                    f.write(f"#EXTINF:-1 tvg-id=\"{name}\" tvg-logo=\"https://p0.ssl.qhimg.com/t01065a244095ef204.png\" group-title=\"{category}\",{name}\n")
                    f.write(f"{url}\n\n")

    # éªŒè¯ç”Ÿæˆç»“æœ
    if os.path.exists(OUTPUT_FILE) and os.path.getsize(OUTPUT_FILE) > 0:
        total_lines = sum(1 for _ in open(OUTPUT_FILE, encoding="utf-8"))
        total_channels = int((total_lines - 1) / 3)  # æ‰£é™¤å¤´éƒ¨ï¼Œæ¯3è¡Œä¸€ä¸ªé¢‘é“
        print(f"âœ… ç”Ÿæˆå®Œæˆï¼{OUTPUT_FILE} | å¯ç”¨é¢‘é“ï¼š{total_channels} ä¸ª | æ–‡ä»¶å¤§å°ï¼š{os.path.getsize(OUTPUT_FILE)/1024:.2f}KB")
        print(f"âœ… æ’­æ”¾å™¨å¯¼å…¥é“¾æ¥ï¼šhttps://raw.githubusercontent.com/ä½ çš„ç”¨æˆ·å/ä½ çš„ä»“åº“å/main/{OUTPUT_FILE}")
    else:
        print(f"âŒ ç”Ÿæˆå¤±è´¥")

if __name__ == "__main__":
    main()
