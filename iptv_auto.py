#!/usr/bin/env python3
# å…¨è‡ªåŠ¨IPTVï¼šæ‹‰å–å…¬å…±æº+å¤šæºæ ¡éªŒ+ä¼˜é€‰+ç”Ÿæˆ æ ¸å¿ƒè„šæœ¬
# æ— éœ€æ‰‹åŠ¨ç»´æŠ¤ï¼Œä¸€é”®æ‰§è¡Œï¼Œå…¨ç¨‹è‡ªåŠ¨åŒ–
import requests
import re
import os
import time
import random
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse

# ===================== é…ç½®é¡¹ï¼ˆå¯æŒ‰éœ€å¾®è°ƒï¼Œé»˜è®¤æ— éœ€ä¿®æ”¹ï¼‰=====================
# å…¨ç½‘ä¼˜è´¨å…¬å…±IPTVæºä»“åº“ï¼ˆå¤šæºå¤‡ä»½ï¼Œæ‹‰å–m3u8æ ¼å¼æºï¼‰
PUBLIC_IPTV_SOURCES = [
    "https://raw.githubusercontent.com/imDazui/Tvlist-awesome-m3u8/master/ipTV.m3u8",
    "https://raw.githubusercontent.com/666wcy/TV/main/tv.m3u8",
    "https://raw.githubusercontent.com/wangrongding/IPTV/master/IPTV.m3u8",
    "https://raw.githubusercontent.com/HeiSir2020/IPTV/main/iptv.m3u8",
    "https://raw.githubusercontent.com/caoxinyu/IPTV/master/iptv.m3u8"
]
# çº¿ç¨‹æ•°ï¼ˆæµ‹é€Ÿå¹¶å‘ï¼ŒæŒ‰éœ€è°ƒæ•´ï¼Œé»˜è®¤10ï¼‰
THREAD_NUM = 10
# è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼Œè¿‡æ»¤è¶…æ—¶æºï¼‰
TIMEOUT = 5
# åŒé¢‘é“ä¼˜é€‰ï¼šä¿ç•™å»¶è¿Ÿæœ€ä½çš„Nä¸ªæºï¼ˆé»˜è®¤1ï¼Œåªç•™æœ€ä¼˜ï¼‰
KEEP_BEST_N = 1
# è¿‡æ»¤æ— æ•ˆé¢‘é“å…³é”®è¯ï¼ˆé¿å…å¹¿å‘Š/æ— æ•ˆå°ï¼‰
FILTER_KEYWORDS = ["å¹¿å‘Š", "æµ‹è¯•", "è´­ç‰©", "ä»˜è´¹", "VIP", "ç ´è§£"]
# è¾“å‡ºæ–‡ä»¶
OUTPUT_FILE = "playlist.m3u8"

# ===================== å·¥å…·å‡½æ•° =====================
# æ‹‰å–å…¬å…±æº
def pull_public_source(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/120.0.0.0 Safari/537.36"}
        res = requests.get(url, headers=headers, timeout=10)
        res.raise_for_status()
        if res.text.startswith("#EXTM3U"):
            print(f"âœ… æˆåŠŸæ‹‰å–æºï¼š{url}")
            return res.text
        else:
            print(f"âŒ éæ ‡å‡†m3u8æºï¼š{url}")
            return None
    except Exception as e:
        print(f"âŒ æ‹‰å–æºå¤±è´¥ {url}ï¼š{str(e)[:50]}")
        return None

# è§£æm3u8ï¼Œæå–é¢‘é“{åç§°: [åœ°å€1, åœ°å€2,...]}
def parse_m3u8(m3u8_content):
    channels = {}
    lines = [line.strip() for line in m3u8_content.split("\n") if line.strip()]
    for i in range(len(lines)):
        if lines[i].startswith("#EXTINF:") and i+1 < len(lines) and not lines[i+1].startswith("#"):
            # æå–é¢‘é“åç§°
            name_match = re.search(r',(.*)$', lines[i])
            if not name_match:
                continue
            channel_name = name_match.group(1).strip()
            # è¿‡æ»¤æ— æ•ˆå…³é”®è¯
            if any(key in channel_name for key in FILTER_KEYWORDS):
                continue
            # æå–æ’­æ”¾åœ°å€
            play_url = lines[i+1].strip()
            # åªä¿ç•™http/https/m3u8æ ¼å¼åœ°å€
            if play_url.startswith(("http://", "https://")) and (".m3u8" in play_url or "hls" in play_url):
                if channel_name not in channels:
                    channels[channel_name] = []
                if play_url not in channels[channel_name]:
                    channels[channel_name].append(play_url)
    print(f"ğŸ“Œ è§£æå®Œæˆï¼Œå…±æå– {len(channels)} ä¸ªé¢‘é“ï¼Œå¾…æ ¡éªŒ")
    return channels

# æµ‹é€Ÿ+å¯ç”¨æ€§æ ¡éªŒï¼ˆæ ¸å¿ƒï¼šè¿‡æ»¤å¤±æ•ˆæºï¼Œè®¡ç®—å»¶è¿Ÿï¼‰
def check_source(channel_name, url):
    try:
        # 1. ç½‘ç»œè¿é€šæ€§æ£€æµ‹
        parsed = urlparse(url)
        start_time = time.time()
        # ç®€å•GETå¤´æ ¡éªŒï¼Œé¿å…å…¨é‡ä¸‹è½½
        requests.head(url, timeout=TIMEOUT, allow_redirects=True)
        delay = round((time.time() - start_time) * 1000, 2)  # å»¶è¿Ÿ(ms)
        print(f"âœ… [{channel_name}] æœ‰æ•ˆ | å»¶è¿Ÿï¼š{delay}ms | {url[:50]}...")
        return (channel_name, url, delay)
    except Exception as e:
        # print(f"âŒ [{channel_name}] å¤±æ•ˆ | {url[:50]}...")
        return None

# ===================== ä¸»é€»è¾‘ï¼šæ‹‰å–â†’è§£æâ†’æ ¡éªŒâ†’ä¼˜é€‰â†’ç”Ÿæˆ =====================
def main():
    print("===== å¼€å§‹å…¨è‡ªåŠ¨IPTVå¤„ç†ï¼šæ‹‰å–å…¬å…±æº =====")
    # 1. æ‰¹é‡æ‹‰å–æ‰€æœ‰å…¬å…±æº
    all_m3u8 = []
    with ThreadPoolExecutor(max_workers=5) as executor:
        futures = [executor.submit(pull_public_source, url) for url in PUBLIC_IPTV_SOURCES]
        for future in as_completed(futures):
            res = future.result()
            if res:
                all_m3u8.append(res)
    if not all_m3u8:
        print("âŒ æ‰€æœ‰å…¬å…±æºæ‹‰å–å¤±è´¥ï¼Œé€€å‡º")
        return
    # åˆå¹¶æ‰€æœ‰æº
    all_m3u8_content = "\n".join(all_m3u8)

    print("===== è§£æé¢‘é“ï¼Œå»é‡ =====")
    # 2. è§£æå¹¶å»é‡
    channels = parse_m3u8(all_m3u8_content)
    if not channels:
        print("âŒ æœªè§£æåˆ°æœ‰æ•ˆé¢‘é“ï¼Œé€€å‡º")
        return

    print("===== å¤šçº¿ç¨‹æ ¡éªŒæºå¯ç”¨æ€§ï¼ˆæµ‹é€Ÿï¼‰ =====")
    # 3. å¤šçº¿ç¨‹æ ¡éªŒæ‰€æœ‰æºï¼Œè¿‡æ»¤å¤±æ•ˆ
    valid_sources = []
    with ThreadPoolExecutor(max_workers=THREAD_NUM) as executor:
        futures = []
        for name, urls in channels.items():
            for url in urls:
                futures.append(executor.submit(check_source, name, url))
        # æ”¶é›†æœ‰æ•ˆç»“æœ
        for future in as_completed(futures):
            res = future.result()
            if res:
                valid_sources.append(res)
    if not valid_sources:
        print("âŒ æ— æœ‰æ•ˆæ’­æ”¾æºï¼Œé€€å‡º")
        return
    print(f"ğŸ“Œ æ ¡éªŒå®Œæˆï¼Œå…±ç­›é€‰å‡º {len(valid_sources)} ä¸ªæœ‰æ•ˆæº")

    print("===== åŒé¢‘é“ä¼˜é€‰ï¼ˆæŒ‰å»¶è¿Ÿæ’åºï¼‰ =====")
    # 4. åŒé¢‘é“æŒ‰å»¶è¿Ÿæ’åºï¼Œä¿ç•™æœ€ä¼˜Nä¸ª
    optimized_channels = {}
    for name, url, delay in valid_sources:
        if name not in optimized_channels:
            optimized_channels[name] = []
        optimized_channels[name].append((url, delay))
    # æ’åº+æˆªå–æœ€ä¼˜Nä¸ª
    for name in optimized_channels:
        # æŒ‰å»¶è¿Ÿå‡åºï¼Œå†æŒ‰åœ°å€é•¿åº¦é™åºï¼ˆä¼˜å…ˆå®Œæ•´æºï¼‰
        optimized_channels[name].sort(key=lambda x: (x[1], -len(x[0])))
        optimized_channels[name] = optimized_channels[name][:KEEP_BEST_N]
    print(f"ğŸ“Œ ä¼˜é€‰å®Œæˆï¼Œæœ€ç»ˆä¿ç•™ {len(optimized_channels)} ä¸ªå¯ç”¨é¢‘é“")

    print("===== ç”Ÿæˆæ ‡å‡†m3u8æ’­æ”¾åˆ—è¡¨ =====")
    # 5. ç”Ÿæˆæ ‡å‡†m3u8æ–‡ä»¶ï¼ˆå¸¦tvg-logoå ä½ï¼Œä¸å½±å“æ’­æ”¾ï¼‰
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write("#EXTM3U x-tvg-url=\"https://epg.112114.xyz/epg.xml\"\n\n")  # å¸¦EPGèŠ‚ç›®å•
        for name, sources in sorted(optimized_channels.items(), key=lambda x: x[0]):
            for url, _ in sources:
                f.write(f"#EXTINF:-1 tvg-logo=\"https://p0.ssl.qhimg.com/t01065a244095ef204.png\",{name}\n")
                f.write(f"{url}\n\n")
    # éªŒè¯æ–‡ä»¶
    if os.path.exists(OUTPUT_FILE) and os.path.getsize(OUTPUT_FILE) > 0:
        total_lines = sum(1 for _ in open(OUTPUT_FILE, encoding="utf-8"))
        total_channels = int(total_lines / 2) - 1  # æ‰£é™¤å¤´éƒ¨
        print(f"âœ… æœ€ç»ˆç”Ÿæˆ {OUTPUT_FILE} | å¯ç”¨é¢‘é“ï¼š{total_channels} ä¸ª | æ–‡ä»¶å¤§å°ï¼š{os.path.getsize(OUTPUT_FILE)/1024:.2f}KB")
    else:
        print(f"âŒ ç”Ÿæˆ {OUTPUT_FILE} å¤±è´¥")

if __name__ == "__main__":
    main()
